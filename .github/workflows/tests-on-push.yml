---

name: Tests on Push


on:
  push:
    branches-ignore:
      - main


jobs:
  tests-on-push:
    runs-on: ubuntu-latest
    steps:

      # Checkout source, install Python, install dependencies
      ######################################################
      - name: Checkout source
        uses: actions/checkout@v3

      - name: Install poetry
        run: | 
          curl -sSL https://install.python-poetry.org | python3 -
          poetry self add poetry-exec-plugin

      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: 3.9
          # restore dependencies from cache (skips step `poetry install` automatically?)
          # see https://github.com/actions/setup-python#caching-packages-dependencies
          cache: poetry

      - name: Install Python dependencies
        run: poetry install
      

      # Build and check docs
      ######################
      - name: build docs
        run: poetry run mkdocs build --strict

      - name: check external links in docs
        run: |
          npm install -g markdown-link-validator
          poetry exec check-links


      # Code Linting
      ##############
      - name: run Pylint
        run: poetry run pylint src

      - name: run mypy
        run: poetry run mypy .

      - name: Lint Code Base
        uses: github/super-linter/slim@v5
        # GitHub's super-linter: https://github.com/github/super-linter
        # super-linter uses a pre-built image with all linters in it. Thus, the linters run outside the poetry virtualenv. 
        # So, pylint reports import-errors for dependencies installed with poetry.
        # In addition, pylint and mypy don't recognize the ignore patterns defined in pyproject.toml.
        # For these reasons, pylint and mypy must be run independently from super-linter.
        env:
          VALIDATE_ALL_CODEBASE: true               # check all files or only edited ones. if false, actions/checkout needs fetch-depth 0
          DEFAULT_BRANCH: main                      # name of the repository default branch; default: master
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # super-linter marks the status of each linter run in the Checks section of a PR
          FILTER_REGEX_EXCLUDE: CHANGELOG\.md       # CHANGELOG.md fails the markdownlint validation
          LINTER_RULES_PATH: /                      # directory for all linter configuration rules; default: .github/linters

          VALIDATE_BASH: true
          VALIDATE_DOCKERFILE_HADOLINT: true        # https://github.com/hadolint/hadolint
          VALIDATE_GITHUB_ACTIONS: true             # https://github.com/rhysd/actionlint
          VALIDATE_JSON: true                       # https://www.npmjs.com/package/eslint-plugin-json
          VALIDATE_MARKDOWN: true                   # https://github.com/igorshubovych/markdownlint-cli
          MARKDOWN_CONFIG_FILE: .markdownlint.yml
          VALIDATE_XML: true                        # http://xmlsoft.org/
          VALIDATE_YAML: true                       # https://github.com/adrienverge/yamllint
          VALIDATE_PYTHON_ISORT: true               # https://pypi.org/project/isort/
          PYTHON_ISORT_CONFIG_FILE: pyproject.toml
          VALIDATE_GITLEAKS: true                   # https://github.com/gitleaks/gitleaks
          # VALIDATE_EDITORCONFIG: true             # https://github.com/editorconfig-checker/editorconfig-checker
          # VALIDATE_JSCPD: true                    # https://github.com/kucherenko/jscpd
          # VALIDATE_JSCPD_ALL_CODEBASE: true       # lint the whole codebase. If false: lint files one by one
          # VALIDATE_NATURAL_LANGUAGE: true         # https://textlint.github.io/
      

      # Install programs for local processing (fast xmlupload)
      ########################################################
      - name: Install ffmpeg for local processing (fast xmlupload)
        uses: FedericoCarboni/setup-ffmpeg@v2

      - name: ImageMagick - get SHA256 of the most recent AppImage
        id: get-imagemagick-sha256
        run: |
          curl -O https://imagemagick.org/archive/binaries/digest.rdf
          value=$(xmllint --xpath 'string(//digest:sha256)' digest.rdf)
          echo "::set-output name=sha256::$value"

      - name: ImageMagick - look for cached AppImage
        # see https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows
        # The first time this runs, no cache is found, so this is skipped, but when all jobs are done, 
        # the files in "path" are cached with "key".
        # In subsequent runs:
        #  - If a cache is found that exactly matches key, the cached files are restored to path.
        #  - If no cache is found with key, restore-keys can partially match cache keys.
        #  - If no cache is found at all, this is skipped, and when all jobs are done, a new cache is created.
        id: search-cached-imagemagick
        uses: actions/cache@v3
        with:
          path: | 
            ~/bin/magick        # AppImage containing all binaries + dependencies
            ~/bin/identify      # don't know where this is located, but I need the "identify" binary somewhere (?)
          key: imagemagick-${{ steps.get-imagemagick-sha256.outputs.sha256 }}
          restore-keys: imagemagick

      - name: ImageMagick - download AppImage
        if: ${{ steps.search-cached-imagemagick.outputs.cache-hit != 'true' }}
        uses: mfinelli/setup-imagemagick@v2  # downloads the "magick" AppImage to ~/bin/magick, unpacks it (?) to have all binaries


      # Run unittests and e2e tests
      #############################
      - name: unittests
        run: poetry run pytest test/unittests/

      - name: e2e tests
        run: |
          poetry run dsp-tools start-stack --no-prune
          poetry run pytest test/e2e/
